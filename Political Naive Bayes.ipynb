{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes on Political Text\n",
    "\n",
    "In this notebook we use Naive Bayes to explore and classify political data. See the `README.md` for full details. You can download the required DB from the shared dropbox or from blackboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/bobbymarriott/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import sqlite3\n",
    "import nltk\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "from collections import Counter, defaultdict\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "punct = set(string.punctuation)\n",
    "from string import punctuation\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import nltk\n",
    "nltk.download('punkt', download_dir='/Users/bobbymarriott/nltk_data')\n",
    "\n",
    "# Feel free to include your text patterns functions\n",
    "#from text_functions_solutions import clean_tokenize, get_patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.data.path.append('/Users/bobbymarriott/nltk_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "convention_db  = sqlite3.connect(\"2020_Conventions.db\")\n",
    "convention_cur = convention_db.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Exploratory Naive Bayes\n",
    "\n",
    "We'll first build a NB model on the convention data itself, as a way to understand what words distinguish between the two parties. This is analogous to what we did in the \"Comparing Groups\" exercise. First, we'll pull in the text \n",
    "for each party and prepare it for use in Naive Bayes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('conventions',)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convention_cur.execute(\"SELECT name FROM sqlite_master WHERE type='table';\").fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('conventions',)]\n",
      "[(0, 'party', 'TEXT', 0, None, 0), (1, 'night', 'INTEGER', 0, None, 0), (2, 'speaker', 'TEXT', 0, None, 0), (3, 'speaker_count', 'INTEGER', 0, None, 0), (4, 'time', 'TEXT', 0, None, 0), (5, 'text', 'TEXT', 0, None, 0), (6, 'text_len', 'TEXT', 0, None, 0), (7, 'file', 'TEXT', 0, None, 0)]\n"
     ]
    }
   ],
   "source": [
    "print(convention_cur.execute(\n",
    "    \"SELECT name FROM sqlite_master WHERE type='table';\"\n",
    ").fetchall())\n",
    "\n",
    "print(convention_cur.execute(\n",
    "    \"PRAGMA table_info(conventions);\"\n",
    ").fetchall())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "990"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convention_data = []\n",
    "\n",
    "# 1. Pull all Dem + Rep speeches\n",
    "query = \"\"\"\n",
    "SELECT text, party\n",
    "  FROM conventions\n",
    " WHERE party IN ('Democrat', 'Republican')\n",
    "\"\"\"\n",
    "convention_cur.execute(query)\n",
    "\n",
    "# 2. Build [speech_text, party] list\n",
    "for speech_text, party in convention_cur.fetchall():\n",
    "    convention_data.append([speech_text, party])\n",
    "\n",
    "len(convention_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it's a best practice to close up your DB connection when you're done\n",
    "convention_db.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at some random entries and see if they look right. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['I’m an example of a woman who has been given a second chance in life. God bless you and God bless America. Good evening. I’m Alice Marie Johnson. I was once told that the only way I would ever be reunited with my family would be as a corpse. But by the grace of God and the compassion of President Donald John Trump, I stand before you tonight, and I assure you I’m not a ghost. I am alive. I am well. And most importantly, I am free. In 1996, I began serving time in prison. Life plus 25 years. I had never been in trouble. I was a first time non-violent offender. What I did was wrong. I made decisions that I regret.',\n",
       "  'Republican'],\n",
       " ['When the pandemic hit, president Trump heard us in our call for assistance for our farmers. Knowing we have an ally in the white house is important. Folks, this election is a choice between two very different paths. Freedom, prosperity, and economic growth under a Trump/Pence administration or the Biden/Harris path, paved by liberal coastal elites and radical environmentalist. An America where farmers are punished, jobs are destroyed and taxes crush the middle class. That is our choice, and it’s a clear one. Thank you and God bless.',\n",
       "  'Republican'],\n",
       " ['I’m going to invite you to join your faith with mine, and let’s pray in agreement. Lord, we come before you to ask for your spirit of peace to come over hurting communities in Wisconsin tonight. We pray for healing and comfort to Jacob Blake and his family. We pray for your protection over those who put their lives in harm’s way, to bring safety and security to our streets. We pray that the truth and justice will be at the heart of all decisions that are made by our leaders, and that we, as a people will seek reconciliation with you, as we do the same with each other. Thank you Lord, for your goodness over our lives, for your blessing over our nation, for your guiding hand over every person that calls the United States of America their home. Lord, we thank you for all that have gone before us and have sowed seeds of sacrifice, for our freedom, for our prosperity and for our peace, those that gave their lives so that we could live and achieve the American dream.',\n",
       "  'Republican'],\n",
       " ['To the media industry and as a country, I ask that we all commit to helping in our fight against drug addiction, by talking about it even more. Especially as we battle the COVID pandemic, we need to remember that suicides are on the rise as people who are struggling with loneliness and addiction feel they have nowhere to turn. Parents, please talk to your children. Teachers and caregivers, pay attention to signs of addiction. Lawmakers, pass legislation that allows those who ask for help to do so safely and without fear, and to provide resources for organizations that help people impacted by addiction. When the stigma is removed, people will no longer be ashamed to ask for help and lives will be saved. And if you are struggling with addiction, there is no shame in your illness. Please seek help. You’re worth it.',\n",
       "  'Republican'],\n",
       " ['My name is Debbie Flood. I own a small foundry and machine shop in Wisconsin, that manufacturers cast bronze architectural hardware. My father, who was a World War II veteran, started the business with some used equipment and the American dream. Today, we are one of the only U.S. companies left, who make our products from start to finish under one roof. We really make things and we love it.',\n",
       "  'Republican']]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.choices(convention_data,k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It'll be useful for us to have a large sample size than 2024 affords, since those speeches tend to be long and contiguous. Let's make a new list-of-lists called `conv_sent_data`. Instead of each first entry in the sublists being an entire speech, make each first entry just a sentence from the speech. Feel free to use NLTK's `sent_tokenize` [function](https://www.nltk.org/api/nltk.tokenize.sent_tokenize.html). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5398\n",
      "[['Skip to content The Company Careers Press Freelancers Blog × Services Transcription Captions Foreign Subtitles Translation Freelancers About Contact Login « Return to Transcript Library home  Transcript Categories  All Transcripts 2020 Election Transcripts Classic Speech Transcripts Congressional Testimony & Hearing Transcripts Debate Transcripts Donald Trump Transcripts Entertainment Transcripts Financial Transcripts Interview Transcripts Political Transcripts Press Conference Transcripts Speech Transcripts Sports Transcripts Technology Transcripts Aug 25, 2020 2020 Republican National Convention (RNC) Night 1 Transcript Rev  ›  Blog  ›  Transcripts  › 2020 Election Transcripts  ›  2020 Republican National Convention (RNC) Night 1 Transcript Night 1 of the Republican National Convention (RNC) on August 24.', 'Republican'], ['Read the transcript of the full event here.', 'Republican'], ['Transcribe Your Own Content  Try Rev for free  and save time transcribing, captioning, and subtitling.', 'Republican'], ['A country where we are judged by our character, with dignity and respect for all.', 'Republican'], ['The belief that all are created equal, that lives matter irrespective of race, creed or color.', 'Republican']]\n"
     ]
    }
   ],
   "source": [
    "conv_sent_data = []\n",
    "# split on any period, question‐mark or exclamation, followed by whitespace\n",
    "sent_split_re = re.compile(r'(?<=[\\.!?])\\s+')\n",
    "\n",
    "for speech, party in convention_data:\n",
    "    # split the speech into sentences\n",
    "    for sent in sent_split_re.split(speech):\n",
    "        sent = sent.strip()\n",
    "        if len(sent) > 10:\n",
    "            conv_sent_data.append([sent, party])\n",
    "\n",
    "print(len(conv_sent_data))\n",
    "print(conv_sent_data[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, let's look at some random entries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['That would teach him not to wear a MAGA hat.', 'Republican'],\n",
       " ['Within three short years, we built the strongest economy in the history of the world.',\n",
       "  'Republican'],\n",
       " ['He was murdered by people who didn’t know and just didn’t care.',\n",
       "  'Republican'],\n",
       " ['Priority, freeing American hostages.', 'Republican'],\n",
       " ['In 2016, Donald Trump made his historic run for the office of United States president.',\n",
       "  'Republican']]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.choices(conv_sent_data,k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's time for our final cleaning before modeling. Go through `conv_sent_data` and take the following steps: \n",
    "\n",
    "1. Tokenize on whitespace\n",
    "1. Remove punctuation\n",
    "1. Remove tokens that fail the `isalpha` test\n",
    "1. Remove stopwords\n",
    "1. Casefold to lowercase\n",
    "1. Join the remaining tokens into a string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('nothing washington', 'Republican'),\n",
       " ('best campaign going', 'Republican'),\n",
       " ('joe biden promises illegal immigrants', 'Republican'),\n",
       " ('old ideas socialism repackaged redefined', 'Republican'),\n",
       " ('wife', 'Republican')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "punct = set(string.punctuation)\n",
    "\n",
    "clean_conv_sent_data = []\n",
    "\n",
    "for idx, (sent, party) in enumerate(conv_sent_data):\n",
    "    # 1. Tokenize on whitespace\n",
    "    tokens = sent.split()\n",
    "    # 2. Remove punctuation tokens\n",
    "    tokens = [t for t in tokens if t not in punct]\n",
    "    # 3. Remove tokens that fail the isalpha() test\n",
    "    tokens = [t for t in tokens if t.isalpha()]\n",
    "    # 4. Remove stopwords\n",
    "    tokens = [t for t in tokens if t.lower() not in stop_words]\n",
    "    # 5. Casefold to lowercase\n",
    "    tokens = [t.lower() for t in tokens]\n",
    "    # 6. Join remaining tokens back into a string\n",
    "    clean_sent = \" \".join(tokens)\n",
    "    \n",
    "    if clean_sent:  # skip empty results\n",
    "        clean_conv_sent_data.append((clean_sent, party))\n",
    "\n",
    "import random\n",
    "random.sample(clean_conv_sent_data, k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If that looks good, let's make our function to turn these into features. First we need to build our list of candidate words. I started my exploration at a cutoff of 5. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With a word cutoff of 5, we have 1109 as features in the model.\n"
     ]
    }
   ],
   "source": [
    "word_cutoff = 5\n",
    "\n",
    "tokens = [w for t, p in clean_conv_sent_data for w in t.split()]\n",
    "\n",
    "word_dist = nltk.FreqDist(tokens)\n",
    "\n",
    "feature_words = set()\n",
    "\n",
    "for word, count in word_dist.items() :\n",
    "    if count > word_cutoff :\n",
    "        feature_words.add(word)\n",
    "        \n",
    "print(f\"With a word cutoff of {word_cutoff}, we have {len(feature_words)} as features in the model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_features(text, fw):\n",
    "    \"\"\"\n",
    "    Given some text, this returns a dictionary holding the feature words.\n",
    "\n",
    "    Args:\n",
    "      * text: a piece of text in a continuous string. Assumes\n",
    "        text has been cleaned and case folded.\n",
    "      * fw: the *feature words* that we're considering. A word in `text`\n",
    "        must be in fw in order to be returned.\n",
    "\n",
    "    Returns:\n",
    "      A dict mapping each feature word found in `text` to True.\n",
    "    \"\"\"\n",
    "    ret_dict = {}\n",
    "    for word in text.split():          # 1) split on whitespace\n",
    "        if word in fw:                 # 2) only keep if it’s one of our features\n",
    "            ret_dict[word] = True      # duplicates automatically collapse\n",
    "    return ret_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(len(feature_words)>0)\n",
    "assert(conv_features(\"obama was the president\",feature_words)==\n",
    "       {'obama':True,'president':True})\n",
    "assert(conv_features(\"some people in america are citizens\",feature_words)==\n",
    "                     {'people':True,'america':True,\"citizens\":True})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll build our feature set. Out of curiosity I did a train/test split to see how accurate the classifier was, but we don't strictly need to since this analysis is exploratory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresets = [(conv_features(text,feature_words), party) for (text, party) in convention_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(20220507)\n",
    "random.shuffle(featuresets)\n",
    "\n",
    "test_size = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "test_set, train_set = featuresets[:test_size], featuresets[test_size:]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "print(nltk.classify.accuracy(classifier, test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a little prose here about what you see in the classifier. Anything odd or interesting?\n",
    "\n",
    "### My Observations\n",
    "\n",
    "Parisan buzzwords such as 'jobs', 'security' drive Republican text while 'inequality' and 'healthcare' drive the Democratic side. Naïve Bayes higlights the signature rhetoric of each party. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Classifying Congressional Tweets\n",
    "\n",
    "In this part we apply the classifer we just built to a set of tweets by people running for congress\n",
    "in 2018. These tweets are stored in the database `congressional_data.db`. That DB is funky, so I'll\n",
    "give you the query I used to pull out the tweets. Note that this DB has some big tables and \n",
    "is unindexed, so the query takes a minute or two to run on my machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "cong_db = sqlite3.connect(\"congressional_data.db\")\n",
    "cong_cur = cong_db.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tables: [('websites',), ('candidate_data',), ('tweets',)]\n",
      "\n",
      "Columns in websites:\n",
      " [(0, 'district', 'TEXT', 0, None, 0), (1, 'candidate', 'TEXT', 0, None, 0), (2, 'pull_time', 'DATETIME', 0, None, 0), (3, 'url', 'TEXT', 0, None, 0), (4, 'site_text', 'TEXT', 0, None, 0)]\n",
      "\n",
      "Columns in candidate_data:\n",
      " [(0, 'index', 'INTEGER', 0, None, 0), (1, 'student', 'TEXT', 0, None, 0), (2, 'state', 'TEXT', 0, None, 0), (3, 'district_num', 'TEXT', 0, None, 0), (4, 'formatted_dist_num', 'INTEGER', 0, None, 0), (5, 'abbrev', 'TEXT', 0, None, 0), (6, 'district', 'TEXT', 0, None, 0), (7, 'candidate', 'TEXT', 0, None, 0), (8, 'party', 'TEXT', 0, None, 0), (9, 'website', 'TEXT', 0, None, 0), (10, 'twitter_handle', 'TEXT', 0, None, 0), (11, 'incumbent', 'TEXT', 0, None, 0), (12, 'age', 'REAL', 0, None, 0), (13, 'gender', 'TEXT', 0, None, 0), (14, 'marital_status', 'TEXT', 0, None, 0), (15, 'white_non_hispanic', 'TEXT', 0, None, 0), (16, 'hispanic', 'TEXT', 0, None, 0), (17, 'black', 'TEXT', 0, None, 0), (18, 'partisian_lean_pvi', 'TEXT', 0, None, 0), (19, 'opposed', 'TEXT', 0, None, 0), (20, 'pct_urban', 'TEXT', 0, None, 0), (21, 'income', 'REAL', 0, None, 0), (22, 'region', 'TEXT', 0, None, 0)]\n",
      "\n",
      "Columns in tweets:\n",
      " [(0, 'district', 'TEXT', 0, None, 0), (1, 'candidate', 'TEXT', 0, None, 0), (2, 'pull_time', 'DATETIME', 0, None, 0), (3, 'tweet_time', 'DATETIME', 0, None, 0), (4, 'handle', 'TEXT', 0, None, 0), (5, 'is_retweet', 'INTEGER', 0, None, 0), (6, 'tweet_id', 'TEXT', 0, None, 0), (7, 'tweet_text', 'TEXT', 0, None, 0), (8, 'likes', 'INTEGER', 0, None, 0), (9, 'replies', 'INTEGER', 0, None, 0), (10, 'retweets', 'INTEGER', 0, None, 0), (11, 'tweet_ratio', 'REAL', 0, None, 0)]\n"
     ]
    }
   ],
   "source": [
    "# 1) List all tables\n",
    "tables = cong_cur.execute(\n",
    "    \"SELECT name FROM sqlite_master WHERE type='table';\"\n",
    ").fetchall()\n",
    "print(\"Tables:\", tables)\n",
    "\n",
    "# 2) For each table, show its columns\n",
    "for (tbl,) in tables:\n",
    "    cols = cong_cur.execute(f\"PRAGMA table_info({tbl});\").fetchall()\n",
    "    print(f\"\\nColumns in {tbl}:\\n\", cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = cong_cur.execute(\"\"\"\n",
    "SELECT DISTINCT\n",
    "  cd.candidate,\n",
    "  cd.party,\n",
    "  tw.tweet_text\n",
    "FROM candidate_data AS cd\n",
    "INNER JOIN tweets AS tw\n",
    "  ON cd.twitter_handle = tw.handle\n",
    "  AND cd.district       = tw.district\n",
    "WHERE cd.party IN ('Republican','Democratic')\n",
    "  AND tw.tweet_text NOT LIKE '%RT%'\n",
    "\"\"\").fetchall()\n",
    "\n",
    "results = list(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "664656 [[b'\"Brooks Joins Alabama Delegation in Voting Against Flawed Funding Bill\" http://t.co/3CwjIWYsNq', 'Republican'], [b'\"Brooks: Senate Democrats Allowing President to Give Americans\\xe2\\x80\\x99 Jobs to Illegals\" #securetheborder https://t.co/mZtEaX8xS6', 'Republican'], [b'\"NASA on the Square\" event this Sat. 11AM \\xe2\\x80\\x93 4PM. Stop by &amp; hear about the incredible work done in #AL05! @DowntownHSV http://t.co/R9zY8WMEpA', 'Republican']]\n"
     ]
    }
   ],
   "source": [
    "tweet_data = []\n",
    "\n",
    "for candidate, party, tweet_text in results:\n",
    "    tweet_data.append([tweet_text, party])\n",
    "\n",
    "# quick check\n",
    "print(len(tweet_data), tweet_data[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a lot of tweets here. Let's take a random sample and see how our classifer does. I'm guessing it won't be too great given the performance on the convention speeches..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(20201014)\n",
    "\n",
    "tweet_data_sample = random.choices(tweet_data,k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's our (cleaned) tweet: earlier spoke house floor abt protecting health care women praised work central\n",
      "Actual party is Democratic and our classifier says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: go\n",
      "Actual party is Democratic and our classifier says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: trump thinks easy students overwhelmed crushing burden debt pay student loans\n",
      "Actual party is Democratic and our classifier says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: grateful first rescue volunteers working tirelessly keep people provide putting lives\n",
      "Actual party is Republican and our classifier says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: make even greater\n",
      "Actual party is Republican and our classifier says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: tie series\n",
      "Actual party is Democratic and our classifier says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: congrats new gig sd city glad continue\n",
      "Actual party is Democratic and our classifier says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: really raised toward match right majors room help us get\n",
      "Actual party is Democratic and our classifier says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: comment period plan expand offshore drilling opened days march share oppose proposed program directly trump comments made email\n",
      "Actual party is Democratic and our classifier says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: celebrated years eastside commitment saluted community leaders last awards\n",
      "Actual party is Democratic and our classifier says Republican.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for tweet, party in tweet_data_sample:\n",
    "    # 1) Decode bytes\n",
    "    if isinstance(tweet, bytes):\n",
    "        tweet = tweet.decode('utf8','ignore')\n",
    "\n",
    "    # 2) Clean\n",
    "    toks = tweet.split()\n",
    "    toks = [\n",
    "        t for t in toks\n",
    "        if t not in punct\n",
    "        and t.isalpha()\n",
    "        and t.lower() not in stop_words\n",
    "    ]\n",
    "    clean = \" \".join(t.lower() for t in toks)\n",
    "\n",
    "    # 3) Featurize & classify\n",
    "    feats = conv_features(clean, feature_words)\n",
    "    estimated_party = classifier.classify(feats)\n",
    "\n",
    "    print(f\"Here's our (cleaned) tweet: {clean}\")\n",
    "    print(f\"Actual party is {party} and our classifier says {estimated_party}.\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've looked at it some, let's score a bunch and see how we're doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first key is actual, second is estimated\n",
    "parties = ['Republican','Democratic']\n",
    "results = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "for p in parties :\n",
    "    for p1 in parties :\n",
    "        results[p][p1] = 0\n",
    "\n",
    "\n",
    "num_to_score = 10000\n",
    "random.shuffle(tweet_data)\n",
    "\n",
    "for idx, (tweet, true_party) in enumerate(tweet_data):\n",
    "    if isinstance(tweet, bytes):\n",
    "        tweet = tweet.decode('utf8', 'ignore')\n",
    "        \n",
    "    toks = tweet.split()\n",
    "    toks = [t for t in toks if t not in punct and t.isalpha() and t.lower() not in stop_words]\n",
    "    clean = \" \".join(t.lower() for t in toks)\n",
    "\n",
    "    feats = conv_features(clean, feature_words)\n",
    "    estimated_party = classifier.classify(feats)\n",
    "    results[true_party][estimated_party] += 1\n",
    "\n",
    "    if idx >= num_to_score:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.<lambda>()>,\n",
       "            {'Republican': defaultdict(int,\n",
       "                         {'Republican': 4278, 'Democratic': 0}),\n",
       "             'Democratic': defaultdict(int,\n",
       "                         {'Republican': 5723, 'Democratic': 0})})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reflections\n",
    "\n",
    "It seems as though the classifier predicts the Republican tweets as True tweets and correctly labeled, however, 0 for the Democratic Tweets. This might show a model reliance on convention-speech and how it fails to capture the linguistic style of the Democrats on Twitter. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
